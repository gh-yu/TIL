# 셀레니움을 이용한 상품정보 크롤링

- 네이버 쇼핑 사이트에서 상품정보를 크롤링해서 엑셀에 저장
- 경쟁사 분석- 쇼핑몰 운영자, 마케팅 관련 종사자

[**학습 순서]**

- requests 한계 : 셀레니움 라이브러리를 사용하는 이유
- 셀레니움 기초 사용법
- 셀레니움 무한 스크롤 처리 방법
- csv 파일로 저장하는 법

## 1. requests 한계 : 셀레니움 라이브러리를 사용하는 이유

### requests 한계

- 로그인이 필요한 사이트인 경우 크롤링이 어려움(session 처리)
- **동적으로 HTML을 만드는 경우** 크롤링이 어려움
    - 스크롤하거나 클릭하면 데이터가 생성됨
    - **URL 주소가 변경되지 않았는데 데이터가 변함**
    - 표, 테이블 형태의 데이터

### 셀레니움


- 웹 어플리케이션 테스트를 위한 도구
- **브라우저를 실제로 띄워서** 사람처럼 동작하도록 만들 수 있다.

<br><br>

## 2. 셀레니움 기초 사용법

### 크롬 드라이버 및 라이브러리 설치

- 크롬 드라이버 다운로드 - [링크](https://chromedriver.chromium.org/downloads) > 자신의 현재 크롬 버전(설정 > 크롬 정보에서 확인)에 맞춰 다운
    
    
- 라이브러리 설치 - `pip install selenium`

<br>

### 최종 코드


```python
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time

# 브라우저 생성
browser = webdriver.Chrome('C:/chromedriver.exe')
# 크롬 브라우저 하나 생성 -> Chrome(크롬드라이버 경로)

# 웹사이트 열기
browser.get('https://www.naver.com')
browser.implicitly_wait(10) # 로딩이 끝날 때까지 10초까지는 기다려줌(클릭 전 로딩 고려)

# 쇼핑 메뉴 클릭
browser.find_element_by_css_selector('a.nav.shop').click()
time.sleep(2) # 페이지 이동 전 검색창 클릭 이벤트 발생될 수 있기 때문에 2초 기다림

# 검색창 클릭
search = browser.find_element_by_css_selector('input.co_srh_input._input')
search.click()

# 검색어 입력 (검색어 입력 후 엔터)
search.send_keys('아이폰 13') 
search.send_keys(Keys.ENTER) # Keys.ENTER : 엔터 치는 명령어
```
<br><br>

## 3. 셀레니움 무한 스크롤 처리 방법

### HTML 분석


- 각 상품 담고 있는 태그
- 상품들 전체 담고 있는 태그
- 스크롤을 했을때 div가 10개가 추가됨→ 동적 사이트

<br>

### **무한 스크롤** 처리 방법 : 무한 반복문(while True:)


- 현재 **스크롤된 높이**를 알 수 있는 자바스크립트 명령어 이용
- `window.scrollY`
    - 콘솔(자바 스크립트를 실행할 수 있는 명령 프롬프트)창에 명령어 입력
        - 명령 프롬프트 : 명령어를 입력하면 대답을 주는 프로그램
    - 명령 결과값의 단위 → 픽셀(px) : 화면을 구성하는 단위
- 스크롤된 최대 높이 구하기 → 범용성을 위한 알고리즘 설계(모든 사이트에 적용 가능하도록)

<br>

### 최종 코드


```python
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time

# 브라우저 생성
browser = webdriver.Chrome('C:/chromedriver.exe')
# 크롬 브라우저 하나 생성 -> Chrome(크롬드라이버 경로)

# 웹사이트 열기
browser.get('https://www.naver.com')
browser.implicitly_wait(10) # 로딩이 끝날 때까지 10초까지는 기다려줌(클릭 전 로딩 고려)

# 쇼핑 메뉴 클릭
browser.find_element_by_css_selector('a.nav.shop').click()
time.sleep(2) # 페이지 이동 전 검색창 클릭 이벤트 발생될 수 있기 때문에 2초 기다림

# 검색창 클릭
search = browser.find_element_by_css_selector('input.co_srh_input._input')
search.click()

# 검색어 입력 (검색어 입력 후 엔터)
search.send_keys('아이폰 13') 
search.send_keys(Keys.ENTER) # Keys.ENTER : 엔터 치는 명령어

# 스크롤 전 높이
before_h = browser.execute_script("return window.scrollY") 
# execute_script() : 자바 스크립트의 명령어 실행
# window.scrollY : 현재 스크롤된 높이 계산하여 반환

# 무한 스크롤 : while 무한 반복문
while True:
    # 맨 아래로 스크롤을 내린다.
    browser.find_element_by_css_selector("body").send_keys(Keys.END)
    # Keys.END : 키보드의 End키, 스크롤을 맨 아래로 내림

    # 스크롤 사이 페이지 로딩 시간
    time.sleep(1) # 각자 컴퓨터 환경, 인터넷 속도에 맞춰 시간 조절

    # 스크롤 후 높이
    after_h = browser.execute_script("return window.scrollY")

    if after_h == before_h:
        break
    before_h = after_h

# 상품 정보 div
items = browser.find_elements_by_css_selector(".basicList_info_area__17Xyo")
# find_elements_by_css_selector() : 여러 개 선택 -> 리스트로 반환

for item in items:
    name = item.find_element_by_css_selector(".basicList_title__3P9Q7").text
    
    # 판매중단된 상품은 가격 정보가 없어서 가져올때 오류가 남
    # try: except: 예외처리 -> 오류가 나는 부분은 except로 처리
    try:
        price = item.find_element_by_css_selector(".price_num__2WUXn").text
    except:
        price = "판매중단"
    
    link = item.find_element_by_css_selector(".basicList_title__3P9Q7 > a").get_attribute('href') # get_attribute('속성명') : 속성값 가지고 옴
    print(name, price, link)
```

<br>

# 4. csv 파일로 저장하는 법


- 파이썬 기본 내장 모듈인 csv import
    - `import csv`
- 파일 생성
    - open() 함수 기본
        - open(file,?mode='r', buffering=None, encoding=None, errors=None, newline=None, closefd=True)
    - `f = open(r"D:\lecture\python_crawling\03_네이버_쇼핑_크롤링\data.csv", 'w', encoding='CP949', newline='')`
        - 첫 번째 인자 file : 파일 경로
        - 두 번째 인자 mode='w' : 쓰기 모드로 파일 열기
        - 세 번째 인자 *encoding='CP949' : 한글 인코딩*
        - *newline='' : window에서 자동으로 추가되는 줄바꿈 문자 없애기*
    - `csvWriter = csv.writer(f)`
- 데이터 쓰기
    - `csvWriter.writerow([name, price, link])`
    - *writerow() : 한 행 추가, 리스트 형태로 인수 전달*
- *파일 닫기*
    - `f.close()`
    

```python
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
import csv

# 브라우저 생성
browser = webdriver.Chrome('C:/chromedriver.exe')
# 크롬 브라우저 하나 생성 -> Chrome(크롬드라이버 경로)

# 웹사이트 열기
browser.get('https://www.naver.com')
browser.implicitly_wait(10) # 로딩이 끝날 때까지 10초까지는 기다려줌(클릭 전 로딩 고려)

# 쇼핑 메뉴 클릭
browser.find_element_by_css_selector('a.nav.shop').click()
time.sleep(2) # 페이지 이동 전 검색창 클릭 이벤트 발생될 수 있기 때문에 2초 기다림

# 검색창 클릭
search = browser.find_element_by_css_selector('input.co_srh_input._input')
search.click()

# 검색어 입력 (검색어 입력 후 엔터)
search.send_keys('아이폰 13') 
search.send_keys(Keys.ENTER) # Keys.ENTER : 엔터 치는 명령어

# 스크롤 전 높이
before_h = browser.execute_script("return window.scrollY") 
# execute_script() : 자바 스크립트의 명령어 실행
# window.scrollY : 현재 스크롤된 높이 계산하여 반환

# 무한 스크롤 : while 무한 반복문
while True:
    # 맨 아래로 스크롤을 내린다.
    browser.find_element_by_css_selector("body").send_keys(Keys.END)
    # Keys.END : 키보드의 End키, 스크롤을 맨 아래로 내림

    # 스크롤 사이 페이지 로딩 시간
    time.sleep(1) # 각자 컴퓨터 환경, 인터넷 속도에 맞춰 시간 조절

    # 스크롤 후 높이
    after_h = browser.execute_script("return window.scrollY")

    if after_h == before_h:
        break
    before_h = after_h

# 파일 생성
f = open(r"D:\lecture\python_crawling\03_네이버_쇼핑_크롤링\data.csv", 'w', encoding='CP949', newline='')
# 'w' : 쓰기 모드
# encoding='CP949' : 한글 인코딩
# newline='' : window에서 자동으로 추가되는 줄바꿈 문자 없애기
csvWriter = csv.writer(f) # writer객체 생성

# 상품 정보 div
items = browser.find_elements_by_css_selector(".basicList_info_area__17Xyo")
# find_elements_by_css_selector() : 여러 개 선택 -> 리스트로 반환

for item in items:
    name = item.find_element_by_css_selector(".basicList_title__3P9Q7").text
    
    # 판매중단된 상품은 가격 정보가 없어서 가져올때 오류가 남
    # try: except: 예외처리 -> 오류가 나는 부분은 except로 처리
    try:
        price = item.find_element_by_css_selector(".price_num__2WUXn").text
    except:
        price = "판매중단"
    
    link = item.find_element_by_css_selector(".basicList_title__3P9Q7 > a").get_attribute('href') # get_attribute('속성명') : 속성값 가지고 옴
    print(name, price, link)
    # 데이터 쓰기
    csvWriter.writerow([name, price, link]) # writerow() : 한 행 추가, 리스트 형태로 인수 전달

# 파일 닫기
f.close()
```